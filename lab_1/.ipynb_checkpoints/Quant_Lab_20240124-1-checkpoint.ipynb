{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "425be6bf-4da8-4bc2-8246-dcd363fe544b",
   "metadata": {
    "id": "425be6bf-4da8-4bc2-8246-dcd363fe544b"
   },
   "source": [
    "# Quantitative Biology and Biophysics (AS.020.674/618)\tSpring 2024\n",
    "## Lab #1\n",
    "## January 26, 2024\n",
    "\n",
    "#  Distributions and Approximations\n",
    "\n",
    "In class, we discussed the binomial distribution, and how if we have a large N, it approximates a continuous distribution that can approximate a Gaussian distribution. We also discussed some useful approximations: Sterlings approximation & the Taylor Expansion. In this lab, you will explore the properties of these distributions and approximations to hopefully gain a better understanding of their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e97c8-5010-4327-8394-ab9a4c4f9fa8",
   "metadata": {
    "id": "2f3e97c8-5010-4327-8394-ab9a4c4f9fa8"
   },
   "source": [
    "# Libraries you will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da35912-055a-41e4-8ce9-8d0fcec99342",
   "metadata": {
    "id": "2da35912-055a-41e4-8ce9-8d0fcec99342"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns #for graphingModuleNotFoundError: No module named 'seaborn'\n",
    "\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import binom\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm #print where you are at when running a for loop\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02c62f",
   "metadata": {},
   "source": [
    "# Discrete vs. Continuous variables\n",
    "\n",
    "When creating vectors, sometimes you need to create vectors of discrete variables (such as number of animals) vs. continuous variables (such as mass). There are two useful functions for doing this:\n",
    "\n",
    " ### For discrete values:\n",
    "\n",
    "`np.arange(start,end_exclusive)`\n",
    "\n",
    "Example: `np.arange(0,10)` will produce a vector of integers from 0 to 9\n",
    "\n",
    "\n",
    " ### For continuous values:\n",
    "\n",
    "`np.linspace(start,end_inclusive)`\n",
    "\n",
    "Example: `np.linspace(0,10)` will produce a vector of 50 evenly spaced values from 0 to 10. The default number of values is 50, so if you want to specify this for X evenly spaced values, use `np.linspace(0,10, num=X)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790f5fa-7feb-488b-90d8-bdb76ae41507",
   "metadata": {
    "id": "b790f5fa-7feb-488b-90d8-bdb76ae41507"
   },
   "source": [
    "# Problem 1: The Binomial Distribution\n",
    "\n",
    "As I mentioned in class, this is a useful distribution when making predictions for binary phenomena. A common problem encountered in biology is making crosses, and deciding how many animals to screen for a particular genotype. Here is a common scenario:\n",
    "\n",
    "You want to make a double recessive mutant for alleles A & B.\n",
    "\n",
    "First, you cross mutant A with mutant B:\n",
    "\n",
    "P0 generation: aaBB x AAbb\n",
    "\n",
    "This produces heterozygous progeny:\n",
    "\n",
    "F1 generation: AaBb\n",
    "\n",
    "You then take siblings from this generation and cross them.\n",
    "\n",
    "**What is the probability of finding an F2 animal that is homozygous dominant for A (i.e. AA)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61a31-f3d3-41e4-90e1-c5068eb60e15",
   "metadata": {
    "id": "3fe61a31-f3d3-41e4-90e1-c5068eb60e15"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 1 point</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b416e5-b248-47a7-84c1-fb785cce7afe",
   "metadata": {
    "id": "d2b416e5-b248-47a7-84c1-fb785cce7afe"
   },
   "outputs": [],
   "source": [
    "AA = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfe376-acaa-41f3-9f54-408527cf2fcd",
   "metadata": {
    "id": "cddfe376-acaa-41f3-9f54-408527cf2fcd"
   },
   "source": [
    "**What is the probability of finding an F2 animal that is homozygous recessive for B (i.e. bb)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422c334-6cf9-4718-ae37-72c26867c850",
   "metadata": {
    "id": "1422c334-6cf9-4718-ae37-72c26867c850"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 1 point</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7831254e-4926-45ff-a01d-4d4b7b2ecedb",
   "metadata": {
    "id": "7831254e-4926-45ff-a01d-4d4b7b2ecedb"
   },
   "outputs": [],
   "source": [
    "bb = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1977560-ff55-4a68-b43f-8f57fff98e1c",
   "metadata": {
    "id": "c1977560-ff55-4a68-b43f-8f57fff98e1c"
   },
   "source": [
    "**What is the probability of finding an F2 animal with the AAbb genotype?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf758e45-33fd-4731-8545-74c4acaa3fe8",
   "metadata": {
    "id": "bf758e45-33fd-4731-8545-74c4acaa3fe8"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 1 point</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71eec117-9264-4513-b709-cec61e8e5652",
   "metadata": {
    "id": "71eec117-9264-4513-b709-cec61e8e5652"
   },
   "outputs": [],
   "source": [
    "# 1/16\n",
    "AAbb = 0.0625"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978cde13-097d-4d0e-9fe1-b60cb0066532",
   "metadata": {
    "id": "978cde13-097d-4d0e-9fe1-b60cb0066532"
   },
   "source": [
    "Let's look at the possible outcomes of picking 20 animals. **Given the above probability, what is the expected mean (µ) probability for picking a double homozygous recessive animal if you pick 20 animals total? What is the variance (σ^2)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2e4a6-069e-4007-9e2b-08632f78f584",
   "metadata": {
    "id": "02d2e4a6-069e-4007-9e2b-08632f78f584"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 3 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b9544b2-d207-4003-87fc-66db0016bea6",
   "metadata": {
    "id": "6b9544b2-d207-4003-87fc-66db0016bea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 1.171875\n"
     ]
    }
   ],
   "source": [
    "p = 0.0625\n",
    "N = 20\n",
    "mu = p*N\n",
    "sigma2 = N*(p*(1-p))\n",
    "print(mu,sigma2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb427be-2750-49d2-896a-681ff2dda80b",
   "metadata": {
    "id": "1cb427be-2750-49d2-896a-681ff2dda80b"
   },
   "source": [
    "**Now let's plot what this distribution of possible outcomes looks like for picking 0->20 animals.** To make the coding easier, rather than coding the entire formula from class, you can use scipy's `binom.pmf` function which you imported above.\n",
    "\n",
    "`P = binom.pmf(k, N, p)`\n",
    "\n",
    "Check to see whether the values for your mean and standard deviation match what you expect with your distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af9eb5-faa6-462e-a6ce-379a95393f37",
   "metadata": {
    "id": "73af9eb5-faa6-462e-a6ce-379a95393f37"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 4 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e2f612-e750-4524-a005-60d56f28f256",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1645154046386,
     "user": {
      "displayName": "Andrew Gordus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBzPoio1jDayY13M5uFDHejsJ1g_w3vXIZqzCiwg=s64",
      "userId": "15332279249794361134"
     },
     "user_tz": 300
    },
    "id": "b7e2f612-e750-4524-a005-60d56f28f256",
    "outputId": "e872b52f-0a38-4767-e984-8fe3bd02877f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'P(k)')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# k needs to be integers\n",
    "\n",
    "k = range(0,N+1)\n",
    "P = binom.pmf(k,N,p)\n",
    "\n",
    "# Plot binomial distribution\n",
    "# Since this is a DISCRETE distribution, you should plot markers, and not lines.\n",
    "# i.e. plt.plot(k,p,'o')\n",
    "\n",
    "plt.plot(k,P,'o')\n",
    "\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('P(k)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9ce63-459c-4600-9f88-4d0976ae7647",
   "metadata": {
    "id": "2ad9ce63-459c-4600-9f88-4d0976ae7647"
   },
   "source": [
    "**What is the probability of NOT finding an aabb F2?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe31bcb-171d-4044-ae55-a39f81826ac8",
   "metadata": {
    "id": "2fe31bcb-171d-4044-ae55-a39f81826ac8"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 1 point</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be3d658b-9057-41b6-b82d-dea58a556842",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1645154051798,
     "user": {
      "displayName": "Andrew Gordus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBzPoio1jDayY13M5uFDHejsJ1g_w3vXIZqzCiwg=s64",
      "userId": "15332279249794361134"
     },
     "user_tz": 300
    },
    "id": "be3d658b-9057-41b6-b82d-dea58a556842",
    "outputId": "384f0f3d-fe30-437d-8069-b3843c755624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2750587898883363\n"
     ]
    }
   ],
   "source": [
    "not_aabb = P[0] \n",
    "print(not_aabb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ee6f8-dadd-4de3-8db8-ff4f05a0cb2d",
   "metadata": {
    "id": "8b2ee6f8-dadd-4de3-8db8-ff4f05a0cb2d"
   },
   "source": [
    "**What is the probability of picking AT LEAST 1 aabb F2?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639edfc-485d-4079-8a38-19477a00f35c",
   "metadata": {
    "id": "d639edfc-485d-4079-8a38-19477a00f35c"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 1 point</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83094954-2fb0-498b-84f8-de61df3f433e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1645154054150,
     "user": {
      "displayName": "Andrew Gordus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBzPoio1jDayY13M5uFDHejsJ1g_w3vXIZqzCiwg=s64",
      "userId": "15332279249794361134"
     },
     "user_tz": 300
    },
    "id": "83094954-2fb0-498b-84f8-de61df3f433e",
    "outputId": "7eca41a5-4e97-4717-e06a-dffb6db9d815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7249412101116637\n"
     ]
    }
   ],
   "source": [
    "p_aabb = 1 - not_aabb\n",
    "print(p_aabb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe343c5-eae7-4b66-8b14-842c9c0de24e",
   "metadata": {
    "id": "ffe343c5-eae7-4b66-8b14-842c9c0de24e"
   },
   "source": [
    "Let's see how the binomial distribution compares to the Gaussian distribution. For this, we will also use a convenient scipy function `norm.pdf` that you imported above. The inputs are k,mean (µ), and standard deviation (the SQUARE ROOT of the variance you calculated above).\n",
    "\n",
    "`P = norm.pdf(k, mu, np.sqrt(sigma2))`\n",
    "\n",
    "**Compare the binomial and Gaussian distributions for `N = 5, 10, 20, 50`, and `p = 0.5`.**\n",
    "\n",
    "For each N:\n",
    "\n",
    "1. Calculate the expected mean.\n",
    "2. Calculate the expected standard deviation.\n",
    "3. Make a subplot with 4 different panels.\n",
    "3. Plot the binomial distribution for the span of N. **'k' should be integers.** Use markers ('o') for this plot.\n",
    "4. Plot the corresponding Gaussian distribution for the span of N as a line. **'k' does not need to be integers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03d278-4fac-44b7-8927-0d7c525e905d",
   "metadata": {
    "id": "4e03d278-4fac-44b7-8927-0d7c525e905d"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 10 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe34a29-a9e6-4936-9fb5-980c1fa078ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1645154058788,
     "user": {
      "displayName": "Andrew Gordus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBzPoio1jDayY13M5uFDHejsJ1g_w3vXIZqzCiwg=s64",
      "userId": "15332279249794361134"
     },
     "user_tz": 300
    },
    "id": "3fe34a29-a9e6-4936-9fb5-980c1fa078ef",
    "outputId": "416c09bd-b2d5-4f5b-ac8c-32c66df70513"
   },
   "outputs": [],
   "source": [
    "\n",
    "P_5 = norm.pdf((range(0,6),mu,np.sqrt(sigma2)))\n",
    "\n",
    "\n",
    "P_10 = norm.pdf((range(0,11),mu,np.sqrt(sigma2)))\n",
    "\n",
    "P_20 = norm.pdf((range(0,21),mu,np.sqrt(sigma2)))\n",
    "\n",
    "P_50 = norm.pdf((range(0,51),mu,np.sqrt(sigma2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ae9dfd-4030-4b92-aa5e-9353881a2dd2",
   "metadata": {
    "id": "c4ae9dfd-4030-4b92-aa5e-9353881a2dd2"
   },
   "source": [
    "# Problem 2: Stirling's Approximation\n",
    "\n",
    "In class, I discussed that Stirling's approximation is a good approximation of N!. Let's see how accurate that statement is. The values of N! grow SUPER LARGE as N grows, so we will compare ln(N!) to Stirling's approximation of ln(N!).\n",
    "\n",
    "Numpy has a factorial function, but it only accepts scalar inputs. To make your life easier, I have had you import scipy's `factorial` function above, which accepts vector inputs.\n",
    "\n",
    "Example:\n",
    "\n",
    "`N = [1,2]`\n",
    "\n",
    "\n",
    "`N_factorial = factorial(N)`\n",
    "\n",
    "**Make 2 Plots:**\n",
    "\n",
    "1. Plot N vs ln(N!), and N vs. Stirling's Approximation of ln(N!) in the same axes.\n",
    "\n",
    "2. Plot N vs. the ratio of absolute difference between ln(N!) and Stirling's approximation to ln(N!).\n",
    "\n",
    "  i.e. |lnN! - Stirling| / lnN!\n",
    "\n",
    "**Have N span 2 to 20. REMEMBER: The values of N must be integers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef5d27-372f-4010-bc5b-fc6e191ceb18",
   "metadata": {
    "id": "4fef5d27-372f-4010-bc5b-fc6e191ceb18"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 13 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a749c-3094-4460-a919-d31d792864ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1645154067054,
     "user": {
      "displayName": "Andrew Gordus",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBzPoio1jDayY13M5uFDHejsJ1g_w3vXIZqzCiwg=s64",
      "userId": "15332279249794361134"
     },
     "user_tz": 300
    },
    "id": "987a749c-3094-4460-a919-d31d792864ce",
    "outputId": "4e13c922-7556-4278-8576-2d1d5a9064db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53768834-7f2a-440c-a19c-c51609b09986",
   "metadata": {
    "id": "53768834-7f2a-440c-a19c-c51609b09986"
   },
   "source": [
    "# Problem 3: Taylor Approximation\n",
    "\n",
    "In class, we discussed the Taylor Approximation of a function. It essentially simplifies a complicated function into a sum of polynomials centered at a point of interest ('a').\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/taylor1.png\" style=\"width: 3000px;\"/>\n",
    "\n",
    "Biological systems (or any system, really) cannot respond infinitely fast to a stimulus. For example, a protein has a time delay when it binds a molecule, and a time delay when it releases the molecule (the on and off rate). The difference between these rates can be considered the \"kernel\" that filters the response to the stimulus. Here is an example of a kernel function:\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/kernel.png\" style=\"width: 200px;\"/>\n",
    "\n",
    "**Let's see what a Taylor Approximation of this function looks like. Please do the following:**\n",
    "\n",
    "1. Plot the function over the span of 0 to 5.\n",
    "2. You'll notice it peaks at a certain point. Calculate this point by taking the derivative of the kernel, setting it to 0, and solving for x. This solution will be 'a'.\n",
    "\n",
    "As a reminder, the derivative of an exponential is:\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/dxex.png\" style=\"width: 200px;\"/>\n",
    "\n",
    "3. Now calculate an approximation of f(x) centered at 'a' by taking the Taylor Approximation to the 1st derivative.\n",
    "4. Calculate an approximation centered at 'a' again, but calculate the Taylor approximation up to the second derivative.\n",
    "5. Plot f(x), and both approximations centered at 'a'. You'll want to set the y limit from 0 to f(a)+0.1 so you can see their relationships better. How good is the approximation near a? Far from it?\n",
    "6. Re-perform steps 3-5, but now calculate the approximation at b = a + 1.\n",
    "\n",
    "To make this easier, I advise that you create 3 functions to calculate f(x), the first derivative, and the second derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A5WAX4tJ4eBN",
   "metadata": {
    "id": "A5WAX4tJ4eBN"
   },
   "source": [
    "## <font color='red'>Student Input Cell: 25 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cb6f9-3d4e-4ab7-b206-a0f55f94a698",
   "metadata": {
    "id": "d38cb6f9-3d4e-4ab7-b206-a0f55f94a698"
   },
   "outputs": [],
   "source": [
    "# Taylor Approximation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b0314",
   "metadata": {},
   "source": [
    "# Problem 4: Plotting Data\n",
    "\n",
    "We want to explore how these data look. To do this we will first plot this data in a variety of ways using seaborn.\n",
    "\n",
    "1.\tProduce a swarm plot of the data. (Since there are 100 data points, I recommend setting the marker size to 2, i.e. `size = 2`\n",
    "2.\tProduce a violin plot of the data.\n",
    "3.\tProduce a box plot of the data.\n",
    "4.\tProduce a bar plot of the data.\n",
    "\n",
    "Since the data are in an excel file, the easiest thing to do is import the data using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0dc344",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72802d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data as dataframe\n",
    "# Data values are the first column of the dataframe, and Data IDs are the second column.\n",
    "\n",
    "file_path = \"/Users/cmdb/Desktop/QBIO_lab/lab_1/bob_pairing_data_2022.xlsx\"\n",
    "\n",
    "fname  = 'bob_pairing_data_2022.xlsx'\n",
    "fname = file_path + fname\n",
    "\n",
    "\n",
    "data_df = pd.read_excel(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b205caa",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 4 seaborn plots\n",
    "# Swarm plot (size = 2)\n",
    "\n",
    "# Violin plot\n",
    "\n",
    "# Box plot\n",
    "\n",
    "# Bar plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8660f9c9",
   "metadata": {},
   "source": [
    "# Problem 5: Model Selection\n",
    "\n",
    "\n",
    "## How to do math with arrays\n",
    "\n",
    "I normally like to work in the realm of arrays, rather than DataFrames. This is because I like to leverage the power and speed of executing linear algebra functions instead of FOR loops. These functions are pre-compiled, so they are much faster. Iteratively going through arrays or DataFrames is computationally exhaustive, and take a long time to run when using large arrays of data.\n",
    "\n",
    "So, first I make a numpy array where the **rows are observations, and columns are samples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5cf980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to numpy array\n",
    "data_n = data_df.to_numpy()\n",
    "data_n = pd.to_numeric(data_n[:,0])\n",
    "data_n.resize(6,100)\n",
    "data_n = np.transpose(data_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc309d",
   "metadata": {},
   "source": [
    "Next, I can compute the mean and standard deviation for every sample with one command, by setting the axis = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea6d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.nanmean(data_n, axis = 0) #calculating mean for every sample - faster than for-loops\n",
    "sigma = np.nanstd(data_n, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa057d7",
   "metadata": {},
   "source": [
    "Isn't that great? Instead of creating a `for` loop and calculating the mean for each column, I simply told the function which axis to use to calculate the mean for the entire array. Both mu and sigma have 6 entries, because I calculated the mean for each column (down the rows, or `axis = 0`). If I had chosen `axis=1`, mu and sigma would be 100 elements long, because I would have calculated the mean and standard deviation of each row.\n",
    "\n",
    "## Gaussian Log Likelihood Function\n",
    "\n",
    "In the last exercise, I showed you how you can simply use the scipy.stats library for calculating common distributions. However, I would like you to get you more accustomed with performing math in python, so **I want you to calculate your own Gaussian probability distribution.**\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/gauss.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "There will be three inputs for your function: `x, mu, sigma`, which will be your `data_n` (x), mean (mu), and standard deviation (sigma).\n",
    "\n",
    "To calculate the Gaussian function, we can again take advantage of using matrices, and negate the need to iteratively perform calculations with a `for` loop. A key detail here is when subtracting the mean (mu) from the columns of data_n. The rows of data_n are observations, and the columns are samples. I want to subtract each element of mu from its corresponding column of data_n, i.e. subtract `mu[0]` from `data_n[:,0]`, and `mu[1]` from `data[:,1]`, etc. \n",
    "\n",
    "Intuitively, you want to do this in a `for` loop. However, normally you could take advantage of linear algebra, and convert mu into a matrix with something called an identity matrix, and then subtract that from data_n, thus bypassing the need for a `for` loop.\n",
    "\n",
    "HOWEVER, Python is accostomed to this, so it does the math for you. If you give it an arithmetic problem between a matrix and a vector, it will look at the length of the vector, and see if the matrix has a dimension with matching length. If it does, it will perform the arithmetic along this dimension. SO, in the example below, when I perform x - mu, Python does all the linear algegra for me. SO CONVENIENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a046bf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5. -5. -5. -5. -5.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 5.  5.  5.  5.  5.]]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "example_data = np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]])\n",
    "mu_test = np.mean(example_data, axis = 0)\n",
    "\n",
    "mean_centered_data = example_data - mu_test\n",
    "\n",
    "print(mean_centered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038bdce",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190dd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gaussian Function\n",
    "\n",
    "def gauss_fun(x,mu,sigma):\n",
    "    # x is a matrix, mu and sigma are vectors\n",
    "    \n",
    "    \n",
    "    return \n",
    "\n",
    "# To confirm your function above is correct, compare it to the solution you get with scipy's function by\n",
    "# printing the absolume difference between the two. Round the answer. Useful functions:\n",
    "# \n",
    "# np.sum\n",
    "# np.abs\n",
    "# np.round\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998a357",
   "metadata": {},
   "source": [
    "Now that you have a function that calculates a Gaussian distribution, create another function that calculates the log-likelihood for that function:\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/gaussian_log2.png\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b1a22",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dbc4bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian logL\n",
    "    \n",
    "def gausslogl(x, mu, sigma):\n",
    "    # x is a matrix, mu and sigma are vectors\n",
    "    \n",
    "    \n",
    "    \n",
    "    return \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143e198",
   "metadata": {},
   "source": [
    "Now you can use your two functions to calculate the log-likelihood function for a Gaussian fit to your data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbdc742",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b546f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd00519",
   "metadata": {},
   "source": [
    "## Double Gaussian Log Likelihood Function\n",
    "\n",
    "Next up is calculating the log likelihood function for the double Gaussian. The double gaussian likelihood function is simply the log of the sum of two Gaussians. HOWEVER, first we need to find the optimal values of w, mu1, mu2, sigma1, and sigma2. Unlike the single gaussian, where we can simply calculate the mean and standard deviation, the double Gaussian does not have analytical solutions for these values.\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/double_gauss.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "This is a common problem in physics. To get around this, you can have your computer find the best approximation for the highest likelihood function. Like we did in class, you want your computer to keep guessing the best parameter values, and choose the values that produce the largest log-likelihood estimate.\n",
    "\n",
    "Most libraries don't have maximize functions, but they DO have MINIMIZE functions (I will explain the reason for this in a future class). However, you can still use a MINIMIZE function to calculate a maximum: you simply optimize your parameters to find the MINIMUM NEGATIVE log-likelihood function.\n",
    "\n",
    "THEREFORE, the function below returns the NEGATIVE of the log-likelihood so that the minimum of this is actually the maximum for the log likelihood function.\n",
    "\n",
    "To have your Double Gaussian log likelihood function in the right format, I am going to start the function for you. **Remember, you can take advantage of the fact you have already written a function to calculate a single Gaussian.**\n",
    "\n",
    "**NOTE: I have put a negative sign on the return value to make sure this function returns the NEGATIVE log-likelihood funciton, since that is what we are going to MINIMIZE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3945af",
   "metadata": {},
   "source": [
    "## <font color='red'>Student Input Cell: 5 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fae9699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Gaussian log likelihood function\n",
    "\n",
    "def dgausslogl(params,x):\n",
    "    \n",
    "\n",
    "    logL = \n",
    "    \n",
    "    return -logL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830f7f9",
   "metadata": {},
   "source": [
    "Next, we will determine the most likely parameters for a double Gaussian for each sample, using the minimize operator. We will then use these parameters to calculate the log likelihood value for each sample. I have to initialize the minimize optimizer with some values, so I use slightly adjusted means and sigmas from the single Gaussians as reasonable guesses.\n",
    "\n",
    "**Notice that when I record the log likelihood for the double Gaussian, I am recording the negative value, since I know the function outputs the negative of the log likelihood function. By recording the negative of a negative, I am recording the positive log liklihood value.**\n",
    "\n",
    "tqdm: Optimizers can take a while to run, so to monitor this, I took advantage of the tqdm toolbar which you imported above.\n",
    "\n",
    "**Since we have not covered optimizers yet, I will calculate the most likely double Gaussian parameters for you, using your function from above.**\n",
    "\n",
    "## Double Gaussian parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logL1 = gausslogl(data_n, mu, sigma)\n",
    "logL2 = np.zeros(np.shape(logL1))\n",
    "\n",
    "params_double = np.zeros((5,6))\n",
    "\n",
    "for m in tqdm(range(len(mu))):\n",
    "    params0 = [mu[m] - sigma[m], mu[m] + sigma[m], sigma[m], sigma[m], 0.6]\n",
    "    result = minimize(dgausslogl, params0, args=data_n[:,m], method='Nelder-Mead')\n",
    "    params_double[:,m] = result.x\n",
    "    logL2[m] = -dgausslogl(result.x,data_n[:,m])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fc762",
   "metadata": {},
   "source": [
    "## BIC Calculation\n",
    "\n",
    "Now that we've calculated the log likelihood functions for both the single and double Gaussian distributions, we're ready to calculate the BIC! Calculate the BIC for the data fit to a single Gaussian, and double Gaussian. Report which model is more likely for each sample.\n",
    "\n",
    "<img src=\"http://www.gordus.org/public_images/bic.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "**Remember, the model that produces the LOWEST BIC is the one that is most likely, RELATIVE to the other models it is compared to.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282351c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <font color='red'>Student Input Cell: 10 points</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d97980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIC: Best model has LOWEST BIC\n",
    "# Print which models are more likely to be single, and double gaussian.\n",
    "\n",
    "\n",
    "\n",
    "def bic_calc(n,k,logL1,logL2):\n",
    "    \n",
    "    return BIC\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2be3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Quant_Lab_20220218_KEY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
